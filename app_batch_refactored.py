"""
=============================================================================
TOOL BATCH - ƒêI·ªÄN NHI·ªÄU GI·∫§Y X√ÅC NH·∫¨N T√åNH TR·∫†NG H√îN NH√ÇN
=============================================================================
·ª®ng d·ª•ng Streamlit ƒë·ªÉ x·ª≠ l√Ω h√†ng lo·∫°t gi·∫•y x√°c nh·∫≠n t√¨nh tr·∫°ng h√¥n nh√¢n
Author: AI Assistant
Version: 2.0 (Refactored)
=============================================================================
"""

import streamlit as st

# C·∫•u h√¨nh Streamlit - PH·∫¢I ƒê·∫∂T ƒê·∫¶U TI√äN
st.set_page_config(
    page_title="Tool ƒêi·ªÅn Gi·∫•y X√°c Nh·∫≠n Batch",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import re
import tempfile
import os
import zipfile
from io import BytesIO
import uuid
import time
import atexit

# =============================================================================
# CONSTANTS & CONFIGURATION
# =============================================================================

TEMP_DIR = tempfile.gettempdir()
MAX_FILES = 5
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

# Session management
SESSION_ID = str(uuid.uuid4())[:8]
TIMESTAMP = int(time.time())
SESSION_FILES = []

def cleanup_session_files():
    """Cleanup temporary files for current session"""
    for file_path in SESSION_FILES:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
        except:
            pass

# Register cleanup on exit
atexit.register(cleanup_session_files)

def get_unique_temp_path(prefix, extension=".docx"):
    """Generate unique temporary file path"""
    filename = f"{prefix}_{SESSION_ID}_{TIMESTAMP}_{int(time.time() * 1000000) % 1000000}{extension}"
    path = os.path.join(TEMP_DIR, filename)
    SESSION_FILES.append(path)
    return path

# Danh s√°ch t·ª´ kh√≥a c·∫ßn lo·∫°i b·ªè khi t√¨m t√™n ng∆∞·ªùi k√Ω
BLACKLIST_KEYWORDS = [
    'CH·ª¶ T·ªäCH', 'PH√ì CH·ª¶ T·ªäCH', 'KT.', 'GI·∫§Y', 'X√ÅC NH·∫¨N', 'T√åNH TR·∫†NG', 
    'H√îN NH√ÇN', 'UBND', '·ª¶Y BAN', 'NH√ÇN D√ÇN', 'S·ªû', 'PH√íNG', 'BAN',
    'C·ªòNG H√íA', 'X√É H·ªòI', 'CH·ª¶ NGHƒ®A', 'VI·ªÜT NAM', 'ƒê·ªòC L·∫¨P', 'T·ª∞ DO',
    'H·∫†NH PH√öC', 'T·ªàNH', 'TH√ÄNH PH·ªê', 'QU·∫¨N', 'HUY·ªÜN', 'X√É', 'PH∆Ø·ªúNG'
]

# H·ªç ph·ªï bi·∫øn Vi·ªát Nam
COMMON_SURNAMES = [
    'Nguy·ªÖn', 'Tr·∫ßn', 'L√™', 'Ph·∫°m', 'Ho√†ng', 'Hu·ª≥nh', 'Phan', 'V≈©', 
    'V√µ', 'ƒê·∫∑ng', 'B√πi', 'ƒê·ªó', 'H·ªì', 'Ng√¥', 'D∆∞∆°ng'
]

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def is_vietnamese_name(text):
    """
    Ki·ªÉm tra xem text c√≥ ph·∫£i t√™n ng∆∞·ªùi Vi·ªát Nam kh√¥ng
    
    Args:
        text (str): Chu·ªói c·∫ßn ki·ªÉm tra
        
    Returns:
        bool: True n·∫øu l√† t√™n ng∆∞·ªùi Vi·ªát Nam h·ª£p l·ªá
    """
    if not text or len(text.strip()) < 3:
        return False
    
    text = text.strip()
    
    # Lo·∫°i b·ªè c√°c t·ª´ kh√≥a c√¥ng vƒÉn
    for word in BLACKLIST_KEYWORDS:
        if word in text.upper():
            return False
    
    # Ki·ªÉm tra pattern t√™n Vi·ªát Nam (2-5 t·ª´, m·ªói t·ª´ b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ hoa)
    words = text.split()
    if len(words) < 2 or len(words) > 5:
        return False
    
    for word in words:
        if not re.match(r'^[A-Z√Ä-·ª∏][a-z√†-·ªπ]*$', word):
            return False
    
    # Kh√¥ng ch·ª©a s·ªë ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
    if re.search(r'[\d\.\,\:\;\!\?\(\)\[\]\{\}]', text):
        return False
    
    return True

def score_name_candidate(name, context, all_lines):
    """
    Ch·∫•m ƒëi·ªÉm ·ª©ng vi√™n t√™n ƒë·ªÉ ch·ªçn t√™n t·ªët nh·∫•t
    
    Args:
        name (str): T√™n ·ª©ng vi√™n
        context (str): D√≤ng ch·ª©a t√™n
        all_lines (list): T·∫•t c·∫£ c√°c d√≤ng trong vƒÉn b·∫£n
        
    Returns:
        int: ƒêi·ªÉm s·ªë c·ªßa ·ª©ng vi√™n
    """
    score = 10  # ƒêi·ªÉm c∆° b·∫£n
    
    # ∆Øu ti√™n t√™n ·ªü cu·ªëi vƒÉn b·∫£n
    try:
        line_index = all_lines.index(context)
        total_lines = len(all_lines)
        if line_index >= total_lines - 3:
            score += 20
        elif line_index >= total_lines - 5:
            score += 10
    except:
        pass
    
    # ∆Øu ti√™n t√™n sau ch·ª©c v·ª•
    if re.search(r'(CH·ª¶ T·ªäCH|PH√ì CH·ª¶ T·ªäCH|KT\.)', context, re.IGNORECASE):
        score += 15
    
    # ∆Øu ti√™n t√™n c√≥ ƒë·ªô d√†i ph√π h·ª£p
    word_count = len(name.split())
    if word_count == 3:
        score += 15
    elif word_count == 2:
        score += 10
    elif word_count == 4:
        score += 5
    
    # Tr·ª´ ƒëi·ªÉm n·∫øu t√™n qu√° ng·∫Øn ho·∫∑c qu√° d√†i
    if len(name) < 6:
        score -= 5
    elif len(name) > 25:
        score -= 10
    
    # ∆Øu ti√™n h·ªç ph·ªï bi·∫øn Vi·ªát Nam
    first_word = name.split()[0]
    if first_word in COMMON_SURNAMES:
        score += 10
    
    return score

def validate_file(file_path):
    """
    Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa file
    
    Args:
        file_path (str): ƒê∆∞·ªùng d·∫´n file
        
    Returns:
        tuple: (is_valid, error_message)
    """
    if not os.path.exists(file_path):
        return False, "File kh√¥ng t·ªìn t·∫°i"
        
    file_size = os.path.getsize(file_path)
    if file_size == 0:
        return False, "File r·ªóng"
    if file_size > MAX_FILE_SIZE:
        return False, "File qu√° l·ªõn (>50MB)"
        
    try:
        doc = Document(file_path)
        return True, None
    except Exception as e:
        return False, f"File kh√¥ng h·ª£p l·ªá: {str(e)}"

# =============================================================================
# DATA EXTRACTION FUNCTIONS
# =============================================================================

def extract_text_from_document(doc_path):
    """
    Tr√≠ch xu·∫•t text t·ª´ file Word
    
    Args:
        doc_path (str): ƒê∆∞·ªùng d·∫´n file Word
        
    Returns:
        str: N·ªôi dung text c·ªßa file
    """
    doc = Document(doc_path)
    
    # L·∫•y text t·ª´ paragraphs
    full_text = '\n'.join([para.text for para in doc.paragraphs])
    
    # L·∫•y text t·ª´ tables
    table_text = ''
    try:
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    table_text += cell.text + '\n'
    except Exception:
        pass
    
    return full_text + '\n' + table_text

def find_person_signature(all_text):
    """
    T√¨m t√™n ng∆∞·ªùi k√Ω b·∫±ng thu·∫≠t to√°n n√¢ng cao
    
    Args:
        all_text (str): To√†n b·ªô n·ªôi dung vƒÉn b·∫£n
        
    Returns:
        tuple: (ten_nguoi_ky, chuc_vu)
    """
    # T√¨m ch·ª©c v·ª•
    chuc_vu = ''
    if re.search(r'KT\.\s*CH·ª¶ T·ªäCH\s*PH√ì CH·ª¶ T·ªäCH', all_text):
        chuc_vu = 'KT. CH·ª¶ T·ªäCH - PH√ì CH·ª¶ T·ªäCH'
    elif re.search(r'PH√ì CH·ª¶ T·ªäCH', all_text):
        chuc_vu = 'PH√ì CH·ª¶ T·ªäCH'
    elif re.search(r'CH·ª¶ T·ªäCH', all_text):
        chuc_vu = 'CH·ª¶ T·ªäCH'
    
    # Thu·∫≠t to√°n t√¨m t√™n n√¢ng cao
    ten_nguoi_ky = ''
    
    # B∆∞·ªõc 1: T√°ch vƒÉn b·∫£n th√†nh c√°c d√≤ng
    lines = [line.strip() for line in all_text.split('\n') if line.strip()]
    
    # B∆∞·ªõc 2: T√¨m v·ªã tr√≠ ch·ª©c v·ª• cu·ªëi c√πng
    chuc_vu_positions = []
    for i, line in enumerate(lines):
        if re.search(r'(KT\.|CH·ª¶ T·ªäCH|PH√ì CH·ª¶ T·ªäCH)', line, re.IGNORECASE):
            chuc_vu_positions.append(i)
    
    # B∆∞·ªõc 3: T√¨m t√™n sau v·ªã tr√≠ ch·ª©c v·ª• cu·ªëi c√πng
    if chuc_vu_positions:
        start_search = chuc_vu_positions[-1] + 1
        
        for i in range(start_search, min(start_search + 5, len(lines))):
            if i < len(lines):
                candidate = lines[i].strip()
                if is_vietnamese_name(candidate):
                    ten_nguoi_ky = candidate
                    break
    
    # B∆∞·ªõc 4: T√¨m trong to√†n b·ªô vƒÉn b·∫£n n·∫øu ch∆∞a c√≥
    if not ten_nguoi_ky:
        name_candidates = []
        
        for line in lines:
            words = line.split()
            for i in range(len(words)):
                for j in range(i+2, min(i+6, len(words)+1)):
                    candidate = ' '.join(words[i:j])
                    if is_vietnamese_name(candidate):
                        name_candidates.append((candidate, line))
        
        if name_candidates:
            scored_candidates = []
            for name, context in name_candidates:
                score = score_name_candidate(name, context, lines)
                scored_candidates.append((score, name))
            
            scored_candidates.sort(reverse=True)
            ten_nguoi_ky = scored_candidates[0][1]
    
    return ten_nguoi_ky, chuc_vu

def extract_field_data(all_text, field_patterns):
    """
    Tr√≠ch xu·∫•t d·ªØ li·ªáu c√°c tr∆∞·ªùng theo patterns
    
    Args:
        all_text (str): N·ªôi dung vƒÉn b·∫£n
        field_patterns (dict): Dictionary ch·ª©a patterns cho t·ª´ng tr∆∞·ªùng
        
    Returns:
        dict: D·ªØ li·ªáu ƒë√£ tr√≠ch xu·∫•t
    """
    data = {}
    
    for field_name, patterns in field_patterns.items():
        data[field_name] = ''
        
        if isinstance(patterns, list):
            for pattern in patterns:
                match = re.search(pattern, all_text)
                if match:
                    data[field_name] = match.group(1).strip()
                    break
        else:
            match = re.search(patterns, all_text)
            if match:
                data[field_name] = match.group(1).strip()
    
    return data

def sanitize_filename(filename):
    """L√†m s·∫°ch t√™n file ƒë·ªÉ tr√°nh l·ªói"""
    import string
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ ch·ªØ, s·ªë, d·∫•u g·∫°ch ngang, g·∫°ch d∆∞·ªõi, ch·∫•m
    valid_chars = "-_. %s%s" % (string.ascii_letters, string.digits)
    filename = ''.join(c for c in filename if c in valid_chars)
    # Thay th·∫ø kho·∫£ng c√°ch b·∫±ng g·∫°ch d∆∞·ªõi
    filename = re.sub(r'\s+', '_', filename)
    return filename

def extract_data_from_input(input_path):
    """
    Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file input
    
    Args:
        input_path (str): ƒê∆∞·ªùng d·∫´n file input
        
    Returns:
        tuple: (data_dict, error_message)
    """
    try:
        # Validate file
        is_valid, error = validate_file(input_path)
        if not is_valid:
            return None, error
        
        # Extract text
        all_text = extract_text_from_document(input_path)
        
        if not all_text.strip():
            return None, "File kh√¥ng c√≥ n·ªôi dung"
        
        # Ki·ªÉm tra lo·∫°i file
        if not re.search(r'GI·∫§Y X√ÅC NH·∫¨N T√åNH TR·∫†NG H√îN NH√ÇN', all_text, re.IGNORECASE):
            return None, "File kh√¥ng ph·∫£i Gi·∫•y x√°c nh·∫≠n t√¨nh tr·∫°ng h√¥n nh√¢n"
        
        # Define field patterns
        field_patterns = {
            'S·ªë': [r'S·ªë:\s*([\w/\-]+)', r'S·ªë\s*:\s*([\w/\-]+)'],
            'H·ªç t√™n': r'H·ªç, ch·ªØ ƒë·ªám, t√™n:\s*([A-Z√Ä-·ª∏\s]+?)(?=\s*Ng√†y|$)',
            'Ng√†y sinh': r'Ng√†y, th√°ng, nƒÉm sinh:\s*(\d+/\d+/\d+)',
            'Gi·ªõi t√≠nh': r'Gi·ªõi t√≠nh:\s*([^\n\r]+?)(?=\s*(?:D√¢n t·ªôc|$))',
            'D√¢n t·ªôc': r'D√¢n t·ªôc:\s*([^\n\r]+?)(?=\s*(?:Qu·ªëc t·ªãch|$))',
            'Qu·ªëc t·ªãch': r'Qu·ªëc t·ªãch:\s*([^\n\r]+?)(?=\s*(?:Gi·∫•y|N∆°i|$))',
            'N∆°i c∆∞ tr√∫': r'N∆°i c∆∞ tr√∫:\s*(.+?)(?=\s*T√¨nh tr·∫°ng|$)',
            'Gi·∫•y t·ªù t√πy th√¢n': r'Gi·∫•y t·ªù t√πy th√¢n:\s*(.+?)(?=\s*N∆°i|$)',
            'T√¨nh tr·∫°ng h√¥n nh√¢n': r'T√¨nh tr·∫°ng h√¥n nh√¢n:\s*(.+?)(?=\s*Gi·∫•y|$)',
            'M·ª•c ƒë√≠ch s·ª≠ d·ª•ng': r's·ª≠ d·ª•ng ƒë·ªÉ:\s*(.+?)(?=\s*Gi·∫•y|$)'
        }
        
        # Extract basic fields
        data = extract_field_data(all_text, field_patterns)
        
        # Extract date
        try:
            date_match = re.search(r'ng√†y\s*(\d+)\s*th√°ng\s*(\d+)\s*nƒÉm\s*(\d+)', all_text)
            data['Ng√†y c·∫•p'] = f"{date_match.group(1)}/{date_match.group(2)}/{date_match.group(3)}" if date_match else ''
        except:
            data['Ng√†y c·∫•p'] = ''
        
        # Extract person signature
        ten_nguoi_ky, chuc_vu = find_person_signature(all_text)
        if ten_nguoi_ky and chuc_vu:
            data['Ng∆∞·ªùi k√Ω'] = f"{ten_nguoi_ky} - {chuc_vu}"
        elif ten_nguoi_ky:
            data['Ng∆∞·ªùi k√Ω'] = ten_nguoi_ky
        elif chuc_vu:
            data['Ng∆∞·ªùi k√Ω'] = chuc_vu
        else:
            data['Ng∆∞·ªùi k√Ω'] = ''
        
        # Set ng∆∞·ªùi ƒë·ªÅ ngh·ªã
        data['Ng∆∞·ªùi ƒë·ªÅ ngh·ªã'] = data['H·ªç t√™n']
        
        # Clean data
        for key in data:
            if isinstance(data[key], str):
                data[key] = data[key].strip()
        
        # Check required fields
        required_fields = ['S·ªë', 'Ng√†y c·∫•p', 'H·ªç t√™n', 'Ng√†y sinh', 'Gi·ªõi t√≠nh', 
                          'D√¢n t·ªôc', 'Qu·ªëc t·ªãch', 'N∆°i c∆∞ tr√∫', 'Gi·∫•y t·ªù t√πy th√¢n', 
                          'T√¨nh tr·∫°ng h√¥n nh√¢n', 'M·ª•c ƒë√≠ch s·ª≠ d·ª•ng', 'Ng∆∞·ªùi k√Ω']
        
        missing_fields = [field for field in required_fields if not data.get(field)]
        
        if missing_fields:
            error_msg = f"Thi·∫øu d·ªØ li·ªáu b·∫Øt bu·ªôc: {', '.join(missing_fields)}"
            return data, error_msg
        
        return data, None
        
    except Exception as e:
        return None, f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}"
# =============================================================================
# TEMPLATE FILLING FUNCTIONS
# =============================================================================

def fill_template(template_path, data, output_docx_path):
    """
    ƒêi·ªÅn d·ªØ li·ªáu v√†o template
    
    Args:
        template_path (str): ƒê∆∞·ªùng d·∫´n file template
        data (dict): D·ªØ li·ªáu c·∫ßn ƒëi·ªÅn
        output_docx_path (str): ƒê∆∞·ªùng d·∫´n file output
        
    Returns:
        bool: True n·∫øu th√†nh c√¥ng
    """
    try:
        if not os.path.exists(template_path):
            return False
            
        doc = Document(template_path)
        
        # Fill data in tables
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    try:
                        cell_text = cell.text
                        
                        # Replace specific patterns
                        if 'S·ªë:' in cell_text and data.get('S·ªë'):
                            cell.text = re.sub(r'S·ªë:\s*[.‚Ä¶‚Ä¶‚Ä¶_\-]+', f"S·ªë: {data['S·ªë']}", cell_text, count=1)
                        
                        if 'Ng√†y, th√°ng, nƒÉm c·∫•p:' in cell_text and data.get('Ng√†y c·∫•p'):
                            cell.text = re.sub(r'Ng√†y, th√°ng, nƒÉm c·∫•p:\s*[.‚Ä¶‚Ä¶‚Ä¶/\-]+', f"Ng√†y, th√°ng, nƒÉm c·∫•p: {data['Ng√†y c·∫•p']}", cell_text, count=1)
                        
                        if 'H·ªç, ch·ªØ ƒë·ªám, t√™n:' in cell_text and data.get('H·ªç t√™n'):
                            cell.text = re.sub(r'H·ªç, ch·ªØ ƒë·ªám, t√™n:\s*[.‚Ä¶‚Ä¶‚Ä¶‚Ä¶]+', f"H·ªç, ch·ªØ ƒë·ªám, t√™n: {data['H·ªç t√™n']}", cell_text)
                        
                        if 'H·ªç, ch·ªØ ƒë·ªám, t√™n, ch·ª©c v·ª• ng∆∞·ªùi k√Ω' in cell_text and data.get('Ng∆∞·ªùi k√Ω'):
                            cell.text = re.sub(r'H·ªç, ch·ªØ ƒë·ªám, t√™n, ch·ª©c v·ª• ng∆∞·ªùi k√Ω[^:]*:\s*[.‚Ä¶‚Ä¶‚Ä¶‚Ä¶]+', f"H·ªç, ch·ªØ ƒë·ªám, t√™n, ch·ª©c v·ª• ng∆∞·ªùi k√Ω Gi·∫•y x√°c nh·∫≠n t√¨nh tr·∫°ng h√¥n nh√¢n: {data['Ng∆∞·ªùi k√Ω']}", cell_text, count=1)
                        
                        # Flexible string replacement for different dot formats
                        if 'Gi·ªõi t√≠nh:' in cell_text and data.get('Gi·ªõi t√≠nh'):
                            # Try multiple dot patterns
                            patterns = ['Gi·ªõi t√≠nh: ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.', 'Gi·ªõi t√≠nh:‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.']
                            for pattern in patterns:
                                if pattern in cell_text:
                                    cell.text = cell_text.replace(pattern, f"Gi·ªõi t√≠nh: {data['Gi·ªõi t√≠nh']}")
                                    break
                        
                        if 'D√¢n t·ªôc:' in cell.text and data.get('D√¢n t·ªôc'):
                            patterns = ['D√¢n t·ªôc: ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.', 'D√¢n t·ªôc:‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.']
                            for pattern in patterns:
                                if pattern in cell.text:
                                    cell.text = cell.text.replace(pattern, f"D√¢n t·ªôc: {data['D√¢n t·ªôc']}")
                                    break
                        
                        if 'Qu·ªëc t·ªãch:' in cell.text and data.get('Qu·ªëc t·ªãch'):
                            patterns = ['Qu·ªëc t·ªãch: ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.', 'Qu·ªëc t·ªãch:‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.']
                            for pattern in patterns:
                                if pattern in cell.text:
                                    cell.text = cell.text.replace(pattern, f"Qu·ªëc t·ªãch: {data['Qu·ªëc t·ªãch']}")
                                    break
                        
                        # Fill other fields
                        field_mappings = [
                            ('Ng√†y, th√°ng, nƒÉm sinh:', 'Ng√†y sinh'),
                            ('N∆°i c∆∞u tr√∫:', 'N∆°i c∆∞ tr√∫'),
                            ('Gi·∫•y t·ªù t√πy th√¢n:', 'Gi·∫•y t·ªù t√πy th√¢n'),
                            ('T√¨nh tr·∫°ng h√¥n nh√¢n:', 'T√¨nh tr·∫°ng h√¥n nh√¢n'),
                            ('M·ª•c ƒë√≠ch s·ª≠ d·ª•ng:', 'M·ª•c ƒë√≠ch s·ª≠ d·ª•ng')
                        ]
                        
                        for field_name, data_key in field_mappings:
                            if field_name in cell_text and data.get(data_key):
                                # Simple pattern like original code
                                pattern = field_name.replace(':', r':\s*[.‚Ä¶‚Ä¶‚Ä¶‚Ä¶]+')
                                cell.text = re.sub(pattern, f"{field_name} {data[data_key]}", cell_text, count=1)
                    except:
                        continue
        
        # Set font formatting
        try:
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            # CƒÉn ph·∫£i cho ng√†y c·∫•p
                            if 'Ng√†y, th√°ng, nƒÉm c·∫•p:' in cell.text:
                                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                            
                            for run in paragraph.runs:
                                try:
                                    run.font.name = 'Times New Roman'
                                    run.font.size = Pt(13)
                                    if 'H·ªç, ch·ªØ ƒë·ªám, t√™n, ch·ª©c v·ª• ng∆∞·ªùi k√Ω' in cell.text:
                                        run.font.bold = True
                                except:
                                    continue
        except:
            pass
        
        doc.save(output_docx_path)
        return True
        
    except Exception:
        return False

# =============================================================================
# STREAMLIT UI FUNCTIONS
# =============================================================================

def render_custom_css():
    """Render custom CSS cho giao di·ªán"""
    st.markdown("""
    <style>
        .main-header {
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            text-align: center;
            color: white;
        }
        .upload-section {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 10px;
            border-left: 4px solid #007bff;
            margin: 1rem 0;
        }
        .success-box {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 8px;
            padding: 1rem;
            margin: 0.5rem 0;
        }
        .error-box {
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            border-radius: 8px;
            padding: 1rem;
            margin: 0.5rem 0;
        }
        .info-box {
            background: #e2f3ff;
            border: 1px solid #b8daff;
            border-radius: 8px;
            padding: 1rem;
            margin: 0.5rem 0;
        }
        .stats-card {
            background: white;
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            text-align: center;
            margin: 0.5rem;
        }
    </style>
    """, unsafe_allow_html=True)

def render_header():
    """Render header ch√≠nh"""
    st.markdown(f"""
    <div class="main-header">
        <h1>üèõÔ∏è Tool Batch - X·ª≠ L√Ω Gi·∫•y X√°c Nh·∫≠n</h1>
        <p>ƒêi·ªÅn nhi·ªÅu gi·∫•y x√°c nh·∫≠n t√¨nh tr·∫°ng h√¥n nh√¢n c√πng l√∫c m·ªôt c√°ch nhanh ch√≥ng v√† ch√≠nh x√°c</p>
        <small style="opacity: 0.7;">Session: {SESSION_ID}</small>
    </div>
    """, unsafe_allow_html=True)

def render_file_upload_section():
    """Render section upload file d·ªØ li·ªáu"""
    st.markdown("""
    <div class="upload-section">
        <h3> B∆∞·ªõc 1: Upload File D·ªØ Li·ªáu</h3>
        <p>Ch·ªçn t·ªëi ƒëa 5 file .docx ch·ª©a th√¥ng tin c·∫ßn ƒëi·ªÅn</p>
    </div>
    """, unsafe_allow_html=True)
    
    return st.file_uploader(
        "", 
        type="docx", 
        accept_multiple_files=True,
        help="K√©o th·∫£ ho·∫∑c click ƒë·ªÉ ch·ªçn file (t·ªëi ƒëa 5MB m·ªói file)",
        key="input_files"
    )

def render_template_upload_section():
    """Hi·ªÉn th·ªã th√¥ng tin template c·ªë ƒë·ªãnh"""
    st.markdown("<br>", unsafe_allow_html=True)
    st.markdown("""
    <div class="upload-section">
        <h3>üìã Template C·ªë ƒê·ªãnh</h3>
        <p> Tool s·ª≠ d·ª•ng template ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho gi·∫•y x√°c nh·∫≠n t√¨nh tr·∫°ng h√¥n nh√¢n</p>
        <p> Kh√¥ng c·∫ßn upload template - ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t s·∫µn</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n template c·ªë ƒë·ªãnh
    return "temp/mau.docx"

def display_file_stats(valid_count, error_count):
    """Hi·ªÉn th·ªã th·ªëng k√™ file"""
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"""
        <div class="stats-card" style="background: #d4edda;">
            <h3 style="color: #155724;">{valid_count}</h3>
            <p>File h·ª£p l·ªá</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stats-card" style="background: #f8d7da;">
            <h3 style="color: #721c24;">{error_count}</h3>
            <p>File c√≥ l·ªói</p>
        </div>
        """, unsafe_allow_html=True)

def display_data_details(data_list, error_list):
    """Hi·ªÉn th·ªã chi ti·∫øt d·ªØ li·ªáu"""
    if data_list:
        with st.expander(f" Xem chi ti·∫øt {len(data_list)} file h·ª£p l·ªá", expanded=False):
            for i, data in enumerate(data_list):
                st.markdown(f"**üìÑ {data['file_name']}**")
                
                col1, col2 = st.columns(2)
                data_items = list(data.items())
                mid = len(data_items) // 2
                
                with col1:
                    for k, v in data_items[:mid]:
                        if k not in ['file_name', 'file_index']:
                            st.write(f"**{k}:** {v}")
                
                with col2:
                    for k, v in data_items[mid:]:
                        if k not in ['file_name', 'file_index']:
                            st.write(f"**{k}:** {v}")
                
                if i < len(data_list) - 1:
                    st.divider()
    
    if error_list:
        with st.expander(f"‚ùå Xem chi ti·∫øt {len(error_list)} file c√≥ l·ªói", expanded=False):
            for error_info in error_list:
                st.markdown(f"""
                <div class="error-box">
                    <h4>üìÑ {error_info['file_name']}</h4>
                    <p><strong>L·ªói:</strong> {error_info['error']}</p>
                </div>
                """, unsafe_allow_html=True)
                
                if error_info['data']:
                    st.write("**D·ªØ li·ªáu ƒë·ªçc ƒë∆∞·ª£c (kh√¥ng ƒë·∫ßy ƒë·ªß):**")
                    col1, col2 = st.columns(2)
                    data_items = list(error_info['data'].items())
                    mid = len(data_items) // 2
                    
                    with col1:
                        for k, v in data_items[:mid]:
                            if k not in ['file_name', 'file_index']:
                                st.write(f"**{k}:** {v}")
                    
                    with col2:
                        for k, v in data_items[mid:]:
                            if k not in ['file_name', 'file_index']:
                                st.write(f"**{k}:** {v}")

def render_footer():
    """Render footer v·ªõi h∆∞·ªõng d·∫´n"""
    st.markdown("<br><br>", unsafe_allow_html=True)
    st.markdown("""
    <div style="background: #f8f9fa; padding: 2rem; border-radius: 10px; border-top: 3px solid #007bff;">
        <h3 style="color: #007bff; margin-bottom: 1rem;">üí° H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng</h3>
        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1rem;">
            <div style="background: white; padding: 1rem; border-radius: 8px; border-left: 4px solid #28a745;">
                <h4 style="color: #28a745; margin: 0;">B∆∞·ªõc 1</h4>
                <p style="margin: 0.5rem 0 0 0;">Upload t·ªëi ƒëa 5 file d·ªØ li·ªáu (.docx)</p>
            </div>
            <div style="background: white; padding: 1rem; border-radius: 8px; border-left: 4px solid #ffc107;">
                <h4 style="color: #ffc107; margin: 0;">B∆∞·ªõc 2</h4>
                <p style="margin: 0.5rem 0 0 0;">Upload 1 file template d√πng chung</p>
            </div>
            <div style="background: white; padding: 1rem; border-radius: 8px; border-left: 4px solid #dc3545;">
                <h4 style="color: #dc3545; margin: 0;">B∆∞·ªõc 3</h4>
                <p style="margin: 0.5rem 0 0 0;">Nh·∫•n 'X·ª≠ L√Ω' v√† t·∫£i file ZIP</p>
            </div>
        </div>
        <div style="margin-top: 1rem; padding: 1rem; background: #e9ecef; border-radius: 8px;">
            <p style="margin: 0; color: #6c757d; text-align: center;">
                <strong>L∆∞u √Ω:</strong> Ch·ªâ file h·ª£p l·ªá m·ªõi ƒë∆∞·ª£c x·ª≠ l√Ω. File c√≥ l·ªói s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã chi ti·∫øt ƒë·ªÉ b·∫°n c√≥ th·ªÉ s·ª≠a ch·ªØa.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)
# =============================================================================
# MAIN APPLICATION
# =============================================================================

def main():
    """H√†m ch√≠nh c·ªßa ·ª©ng d·ª•ng"""
    
    # Render UI components
    render_custom_css()
    render_header()
    
    # Step 1: Upload input files
    uploaded_inputs = render_file_upload_section()
    
    data_list = []
    error_list = []
    
    if uploaded_inputs:
        # Validate file count
        if len(uploaded_inputs) > MAX_FILES:
            st.error(f"‚ùå Ch·ªâ ƒë∆∞·ª£c upload t·ªëi ƒëa {MAX_FILES} file!")
            uploaded_inputs = uploaded_inputs[:MAX_FILES]
        
        # Process files with progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, uploaded_file in enumerate(uploaded_inputs):
            progress_bar.progress((i + 1) / len(uploaded_inputs))
            status_text.text(f'ƒêang x·ª≠ l√Ω: {uploaded_file.name}')
            
            if uploaded_file.name.lower().endswith('.docx'):
                # T·∫°o t√™n file t·∫°m th·ªùi unique
                input_path = get_unique_temp_path(f"input_{i}")
                try:
                    with open(input_path, "wb") as f:
                        f.write(uploaded_file.getvalue())
                    
                    data, error = extract_data_from_input(input_path)
                    if data and not error:
                        data['file_name'] = uploaded_file.name
                        data['file_index'] = i + 1
                        data_list.append(data)
                    else:
                        error_info = {
                            'file_name': uploaded_file.name,
                            'error': error or "Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu",
                            'data': data
                        }
                        error_list.append(error_info)
                except Exception as e:
                    error_info = {
                        'file_name': uploaded_file.name,
                        'error': f"L·ªói x·ª≠ l√Ω: {str(e)}",
                        'data': None
                    }
                    error_list.append(error_info)
            else:
                error_info = {
                    'file_name': uploaded_file.name,
                    'error': "Kh√¥ng ph·∫£i file .docx",
                    'data': None
                }
                error_list.append(error_info)
        
        progress_bar.empty()
        status_text.empty()
        
        # Display results
        display_file_stats(len(data_list), len(error_list))
        display_data_details(data_list, error_list)
    
    # Step 2: Upload template
    uploaded_template = render_template_upload_section()
    template_path = None
    
    if uploaded_template:
        # uploaded_template b√¢y gi·ªù l√† ƒë∆∞·ªùng d·∫´n string, kh√¥ng ph·∫£i file object
        template_path = uploaded_template
        try:
            # Ki·ªÉm tra file template c√≥ t·ªìn t·∫°i kh√¥ng
            if os.path.exists(template_path):
                test_doc = Document(template_path)
                st.markdown("""
                <div class="success-box">
                    <h4>‚úÖ Template ƒë√£ s·∫µn s√†ng</h4>
                    <p>Template c·ªë ƒë·ªãnh ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                raise FileNotFoundError(f"Template file kh√¥ng t·ªìn t·∫°i: {template_path}")
        except Exception as e:
            st.markdown(f"""
            <div class="error-box">
                <h4>‚ùå Template kh√¥ng h·ª£p l·ªá</h4>
                <p>{str(e)}</p>
            </div>
            """, unsafe_allow_html=True)
            template_path = None
    
    # Step 3: Process files
    st.markdown("<br>", unsafe_allow_html=True)
    
    if data_list and template_path:
        st.markdown("""
        <div class="info-box">
            <h3> B∆∞·ªõc 3: X·ª≠ L√Ω File</h3>
            <p>T·∫•t c·∫£ ƒë√£ s·∫µn s√†ng! Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu x·ª≠ l√Ω</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Display metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("File h·ª£p l·ªá", len(data_list))
        with col2:
            st.metric("File c√≥ l·ªói", len(error_list))
        with col3:
            st.metric("T·ªïng c·ªông", len(data_list) + len(error_list))
        
        if error_list:
            st.warning(f"‚ö†Ô∏è {len(error_list)} file c√≥ l·ªói s·∫Ω b·ªã b·ªè qua")
        
        # Process button
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            process_button = st.button(
                f" X·ª≠ L√Ω {len(data_list)} File H·ª£p L·ªá", 
                type="primary",
                use_container_width=True
            )
        
        if process_button:
            # Process files with progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            zip_buffer = BytesIO()
            used_names = {}
            processed_files = []  # T·∫°o list ƒë·ªÉ l∆∞u file ƒë√£ x·ª≠ l√Ω
            
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                success_count = 0
                
                for i, data in enumerate(data_list):
                    progress_bar.progress((i + 1) / len(data_list))
                    status_text.text(f'ƒêang x·ª≠ l√Ω: {data["file_name"]}')
                    
                    try:
                        output_path = get_unique_temp_path(f"output_{i}")
                        
                        if fill_template(template_path, data, output_path):
                            # Generate unique filename v·ªõi sanitize
                            ho_ten = data.get('H·ªç t√™n', f'File_{data["file_index"]}')
                            ho_ten_clean = sanitize_filename(ho_ten)
                            base_name = f"{ho_ten_clean}_GiayXacNhan"
                            
                            if base_name in used_names:
                                used_names[base_name] += 1
                                zip_filename = f"{base_name}_{used_names[base_name]}.docx"
                            else:
                                used_names[base_name] = 1
                                zip_filename = f"{base_name}.docx"
                            
                            # Sanitize zip filename
                            zip_filename = sanitize_filename(zip_filename)
                            
                            with open(output_path, 'rb') as f:
                                zip_file.writestr(zip_filename, f.read())
                            
                            # Th√™m v√†o processed_files
                            processed_files.append((zip_filename, output_path))
                            success_count += 1
                        else:
                            st.error(f"‚ùå {data['file_name']}: L·ªói khi x·ª≠ l√Ω template")
                    except Exception as e:
                        st.error(f"‚ùå {data['file_name']}: {str(e)}")
            
            progress_bar.empty()
            status_text.empty()
            zip_buffer.seek(0)
            
            if success_count > 0:
                st.markdown(f"""
                <div class="success-box">
                    <h3>üéâ X·ª≠ L√Ω Ho√†n Th√†nh!</h3>
                    <p>ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng <strong>{success_count}/{len(data_list)}</strong> file h·ª£p l·ªá</p>
                </div>
                """, unsafe_allow_html=True)
                
                # Ch·ªâ l·∫•y file th√†nh c√¥ng (lo·∫°i b·ªè file l·ªói)
                success_files = [(name, path) for name, path in processed_files if os.path.exists(path)]
                
                if success_files:
                    # N√∫t xu·∫•t t·∫•t c·∫£ (ch·ªâ file th√†nh c√¥ng)
                    st.subheader("üì¶ Xu·∫•t T·∫•t C·∫£")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.download_button(
                            f"üìÑ T·∫£i T·∫•t C·∫£ DOCX ({len(success_files)} file)",
                            zip_buffer.getvalue(),
                            file_name="GiayXacNhan_DOCX.zip",
                            mime="application/zip",
                            use_container_width=True
                        )
                
                    
                    # T·∫£i t·ª´ng file ri√™ng l·∫ª (ch·ªâ file th√†nh c√¥ng)
                    st.subheader("üìÑ T·∫£i T·ª´ng File")
                    for i, (filename, file_path) in enumerate(success_files):
                        if os.path.exists(file_path):  # Double check file t·ªìn t·∫°i
                            col1, col2, col3 = st.columns([2, 1, 1])
                            with col1:
                                st.text(f"‚úÖ {filename}")
                            with col2:
                                with open(file_path, 'rb') as f:
                                    st.download_button(
                                        "üìÑ DOCX",
                                        data=f.read(),
                                        file_name=filename,
                                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                        key=f"download_docx_{i}"
                                    )
                        
                
                if error_list:
                    st.warning(f"‚ö†Ô∏è {len(error_list)} file c√≥ l·ªói ƒë√£ b·ªã b·ªè qua. Vui l√≤ng s·ª≠a l·ªói v√† th·ª≠ l·∫°i.")
                
                # Cleanup processed files after download
                try:
                    cleanup_session_files()
                except:
                    pass
            else:
                st.markdown("""
                <div class="error-box">
                    <h3>‚ùå X·ª≠ L√Ω Th·∫•t B·∫°i</h3>
                    <p>Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!</p>
                </div>
                """, unsafe_allow_html=True)
    
    elif data_list and not template_path:
        st.markdown("""
        <div class="info-box">
            <h3>‚è≥ Ch·ªù Template</h3>
            <p>Vui l√≤ng upload file template ƒë·ªÉ ti·∫øp t·ª•c</p>
        </div>
        """, unsafe_allow_html=True)
    elif not data_list and template_path:
        if error_list:
            st.markdown("""
            <div class="error-box">
                <h3>‚ùå T·∫•t C·∫£ File ƒê·ªÅu C√≥ L·ªói</h3>
                <p>Vui l√≤ng ki·ªÉm tra v√† upload l·∫°i file h·ª£p l·ªá</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="info-box">
                <h3>‚è≥ Ch·ªù File D·ªØ Li·ªáu</h3>
                <p>Vui l√≤ng upload c√°c file d·ªØ li·ªáu</p>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="info-box">
            <h3>üöÄ B·∫Øt ƒê·∫ßu</h3>
            <p>Vui l√≤ng upload file d·ªØ li·ªáu v√† template ƒë·ªÉ b·∫Øt ƒë·∫ßu</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Render footer
    render_footer()

if __name__ == "__main__":
    main()
